{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fec18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1afa1c",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "[1. Data preparation](#data_prep)  \n",
    "[2. Creating data structures for face recognition algorithm](#data_structures)\n",
    "  - `df_final`  \n",
    "  - `encodings`   \n",
    "  - `users`   \n",
    "  - `df_test_encodings`  \n",
    "  \n",
    "[3. Measuring different methods' performance](#testing)\n",
    "  - Baseline  \n",
    "  - Mean encodings  \n",
    "  - 5 in a row  \n",
    "  - Face distance threshold    \n",
    "  - Minimum distance  \n",
    "  \n",
    "[4. Conclusions](#conclusions)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666a723",
   "metadata": {},
   "source": [
    "# <a id='data_prep'>1. Data preparation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c66ab",
   "metadata": {},
   "source": [
    "### identity_CelebA dataframe\n",
    "here we have only `filename` column and corresponding `identity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971be343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  identity\n",
       "0  000001.jpg      2880\n",
       "1  000002.jpg      2937\n",
       "2  000003.jpg      8692"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset 'identity_CelebA'\n",
    "df_identity = pd.read_csv('dataset/identity_CelebA.txt', sep=' ', names=['filename', 'identity'])\n",
    "df_identity.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfaec2",
   "metadata": {},
   "source": [
    "leaving only those identities, who have more than 7 photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fd51a180",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution = df_identity['identity'].value_counts()  # counting how many images there are for each identity\n",
    "distr = distribution.loc[distribution > 4]             # leaving identities, who has 7+ images \n",
    "idx_list = distr.index                                 # getting indexes of the left identities\n",
    "len(idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfca48",
   "metadata": {},
   "source": [
    "### Creating the DataFrame, where each row is the identity index and the corresponding filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50a353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_identities_dict(row):\n",
    "    if row['identity'] in identities_dict:\n",
    "        identities_dict[row['identity']][0].append(row['filename'])\n",
    "    else:\n",
    "        identities_dict[row['identity']] = [[row['filename']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d3f3bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 7.99 ms, total: 12.3 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_dict = {}\n",
    "\n",
    "for index, row in df_identity.iterrows():\n",
    "    create_identities_dict(row)\n",
    "\n",
    "# creating identities/filenames DataFrame\n",
    "df_if = pd.DataFrame.from_dict(identities_dict, orient='index').reset_index().rename(columns={\"index\": 'identities', 0: 'filenames'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "041b12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 9343 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>filenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[000001.jpg, 000404.jpg, 003415.jpg, 004390.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[000002.jpg, 011437.jpg, 016335.jpg, 017121.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[000003.jpg, 015648.jpg, 033840.jpg, 038887.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[000004.jpg, 001778.jpg, 010191.jpg, 013676.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[000005.jpg, 008431.jpg, 014427.jpg, 016680.jp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity                                          filenames\n",
       "0      2880  [000001.jpg, 000404.jpg, 003415.jpg, 004390.jp...\n",
       "1      2937  [000002.jpg, 011437.jpg, 016335.jpg, 017121.jp...\n",
       "2      8692  [000003.jpg, 015648.jpg, 033840.jpg, 038887.jp...\n",
       "3      5805  [000004.jpg, 001778.jpg, 010191.jpg, 013676.jp...\n",
       "4      9295  [000005.jpg, 008431.jpg, 014427.jpg, 016680.jp..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_if = df_if.loc[df_if['identities'].isin(idx_list)]\n",
    "print('DataFrame has ' + str(len(df_if)) + ' rows')\n",
    "df_if.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b698f",
   "metadata": {},
   "source": [
    "# <a id='data_structures'>2. Creating data structures for face recognition algorithm</a>\n",
    "We need:  \n",
    "`df_final` - a DataFrame where each identity has 5 face encodings  \n",
    "`encodings` - array of all encodings  \n",
    "`users` - dictionary, where keys are users' idx and the values are the corresponding names/addresses (here these are identities' idx, but in my project it will change)  \n",
    "`df_test_images` - DataFrame with the images that weren't parsed into encodings earlier  \n",
    "`df_test_encodings` - DataFrame with identities and images parsed into encodings  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32071ff",
   "metadata": {},
   "source": [
    "### 2.1 `df_final`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ad35891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_encodings(filename):\n",
    "    \"\"\"\n",
    "        - Gets filename, reads the image, finds faces, creates face encodings\n",
    "        - Returns face encoding, if a face was found on the image\n",
    "    \"\"\"\n",
    "    img = cv2.imread('dataset/img_align_celeba/' + filename)\n",
    "    locations = face_recognition.face_locations(img, model='hog')\n",
    "    encodings_ = face_recognition.face_encodings(img, locations)\n",
    "    return encodings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ae7b95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_image(identity, filenames_list):\n",
    "    \"\"\"\n",
    "        - Gets id of identity and list of filenames, which belongs to identity\n",
    "        - Proceeds a search of non-seen images and trying to recognize face on it\n",
    "        - Goes into recursion, if a face wasn't found\n",
    "        - Returns face encoding and filename of the image, on which the face was recognized\n",
    "    \"\"\"\n",
    "    global seen_images\n",
    "    for filename_ in filenames_list:\n",
    "        if filename_ not in seen_images:\n",
    "            encodings_ = image_to_encodings(filename_)\n",
    "            seen_images.append(filename_)\n",
    "            filenames_list.remove(filename_)\n",
    "            if len(encodings_) != 1:\n",
    "                new_encoding_, new_filename_ = find_new_image(identity, filenames_list)\n",
    "                seen_images.append(new_filename_)\n",
    "                return new_encoding_, new_filename_\n",
    "            return encodings_[0], filename_\n",
    "    return None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "89aa373b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filenames_into_encodings(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        - Takes a DataFrame with columns 'filenames' and 'identities'\n",
    "        - Reads each image, creates face encodings, tries to find new image in case the face wasn't found \n",
    "        or skips damaged images/identities\n",
    "        - Returns:\n",
    "            - `encodings_overall` - list with all encodings\n",
    "            - `errors` - log of images, on which there was 0 or more than 1 faces\n",
    "            - `seen_images_` - list of seen images\n",
    "            - `data_` - dictionary, where keys are identities idx and values are list of 5 face encodings\n",
    "    \"\"\"\n",
    "    encodings_overall = []  # list of all encodings \n",
    "    errors_ = []  # list for images, where weren't located any faces\n",
    "    seen_images_ = []\n",
    "    data_ = {'identities': [], 'encodings': []}\n",
    "\n",
    "    # for identity in df['identity'].iloc[:100].values:\n",
    "    # be careful with the activation of the line below, it takes almost 2 hours to proceed\n",
    "    for identity in df['identities'].values:\n",
    "#         filenames_list = df['filenames'].loc[df['identities'] == identity].values[0]\n",
    "        filenames_list = json.loads(df['filenames'].loc[df['identities'] == identity].values[0])\n",
    "        counter = 0\n",
    "        data_['identities'].append(identity)\n",
    "        temp_encodings = []\n",
    "        for filename in filenames_list:\n",
    "            if counter >= 5:\n",
    "                continue\n",
    "\n",
    "            encodings_ = image_to_encodings(filename)\n",
    "            seen_images_.append(filename)\n",
    "\n",
    "            # if a face wasn't found or there were more than 1 face\n",
    "            if len(encodings_) != 1:\n",
    "                # try to find another image of the same identity\n",
    "                new_encoding, new_filename = find_new_image(identity, filenames_list)\n",
    "\n",
    "                # if there wasn't any other photos\n",
    "                if new_encoding is None:\n",
    "                    # append an error message\n",
    "                    errors_.append(('problem in:', filename, new_filename, identity, 'solved with:', 'ISN\\'T SOLVED'))\n",
    "                else:\n",
    "                    encodings_overall.append(new_encoding)\n",
    "                    temp_encodings.append(list(new_encoding))\n",
    "                    errors_.append(('problem in:', filename, identity, 'solved with:', new_filename))\n",
    "            else:\n",
    "                encodings_overall.append(encodings_[0])\n",
    "                temp_encodings.append(list(encodings_[0]))\n",
    "\n",
    "            counter += 1\n",
    "        data_['encodings'].append(json.dumps(temp_encodings))\n",
    "    return encodings_overall, errors_, seen_images_, data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aad3a013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 28min, sys: 7.35 s, total: 2h 28min 8s\n",
      "Wall time: 2h 35min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encodings, errors, seen_images, data = filenames_into_encodings(df_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5ef131a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48567"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seen_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91957081",
   "metadata": {},
   "source": [
    "Creating and saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7afbd308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.09392920881509781, 0.16680526733398438, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.13565079867839813, 0.04019104316830635, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.08772975206375122, 0.17790649831295013, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.207429900765419, 0.17357361316680908, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.11555222421884537, 0.05275091528892517, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identities                                          encodings\n",
       "0        2880  [[-0.09392920881509781, 0.16680526733398438, 0...\n",
       "1        2937  [[-0.13565079867839813, 0.04019104316830635, 0...\n",
       "2        8692  [[-0.08772975206375122, 0.17790649831295013, 0...\n",
       "3        5805  [[-0.207429900765419, 0.17357361316680908, -0....\n",
       "4        9295  [[-0.11555222421884537, 0.05275091528892517, 0..."
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = pd.DataFrame(data=data, columns=['identities', 'encodings'])\n",
    "df_fin.to_csv('identities_encodings_super_final.csv', index=False)\n",
    "df_fin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7bb8b1",
   "metadata": {},
   "source": [
    "Reading the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a55a85e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.09392920881509781, 0.16680526733398438, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.13565079867839813, 0.04019104316830635, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.08772975206375122, 0.17790649831295013, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.207429900765419, 0.17357361316680908, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.11555222421884537, 0.05275091528892517, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>5920</td>\n",
       "      <td>[[-0.20153068006038666, 0.13730086386203766, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>9268</td>\n",
       "      <td>[[-0.10642589628696442, 0.13724175095558167, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>8052</td>\n",
       "      <td>[[0.06224041059613228, 0.005616001784801483, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>8146</td>\n",
       "      <td>[[-0.12671472132205963, 0.1192317008972168, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>9454</td>\n",
       "      <td>[[-0.030202826485037804, 0.10130798816680908, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings\n",
       "0           2880  [[-0.09392920881509781, 0.16680526733398438, 0...\n",
       "1           2937  [[-0.13565079867839813, 0.04019104316830635, 0...\n",
       "2           8692  [[-0.08772975206375122, 0.17790649831295013, 0...\n",
       "3           5805  [[-0.207429900765419, 0.17357361316680908, -0....\n",
       "4           9295  [[-0.11555222421884537, 0.05275091528892517, 0...\n",
       "...          ...                                                ...\n",
       "9338        5920  [[-0.20153068006038666, 0.13730086386203766, 0...\n",
       "9339        9268  [[-0.10642589628696442, 0.13724175095558167, 0...\n",
       "9340        8052  [[0.06224041059613228, 0.005616001784801483, -...\n",
       "9341        8146  [[-0.12671472132205963, 0.1192317008972168, 0....\n",
       "9342        9454  [[-0.030202826485037804, 0.10130798816680908, ...\n",
       "\n",
       "[9343 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_fin = pd.read_csv('identities_encodings_super_final.csv')\n",
    "df_read_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669157db",
   "metadata": {},
   "source": [
    "Checking how many face encodings each person has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7ea01b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_enc_quant(row):\n",
    "    if len(json.loads(row['encodings'])) != 5:\n",
    "        damaged_rows.append(row['identities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d4c63",
   "metadata": {},
   "source": [
    "Finding the damaged rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "019cc6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damaged_rows = []\n",
    "\n",
    "for index, row in df_read_fin.iterrows():\n",
    "    check_enc_quant(row)\n",
    "    \n",
    "len(damaged_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43ca97",
   "metadata": {},
   "source": [
    "Dropping the damaged rows and saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4dc1c56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9283"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_fin = df_read_fin.loc[~df_read_fin['identities'].isin(damaged_rows)]\n",
    "df_read_fin.to_csv('identities_encodings_super_final2.csv', index=False)\n",
    "len(df_read_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584c73f",
   "metadata": {},
   "source": [
    "### 2.2 `encodings`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f92148",
   "metadata": {},
   "source": [
    "Reading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847156d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9283 unique identities in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_csv('identities_encodings_super_final2.csv')\n",
    "print(f'{len(df_final)} unique identities in the DataFrame')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b11da",
   "metadata": {},
   "source": [
    "Creating list of all encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "850c8f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46415 face encodings in the encodings list\n"
     ]
    }
   ],
   "source": [
    "encodings = []\n",
    "for index, row in df_final.iterrows():\n",
    "    encodings.extend(json.loads(row['encodings']))\n",
    "\n",
    "print(f'{len(encodings)} face encodings in the encodings list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90cd66",
   "metadata": {},
   "source": [
    "### 2.3 `users`:  \n",
    "Creating map:  \n",
    "- from encoding index // 5   \n",
    "- to identity or user's name/address  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c312d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = df_final['identities']\n",
    "users = {key: value for key, value in zip(range(len(user_idx)), user_idx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ad9a4",
   "metadata": {},
   "source": [
    "### 2.4 `df_test_images`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf76361",
   "metadata": {},
   "source": [
    "Creating new DataFrame, which consists of images, which weren't seen during creation of the main dataset (`df_final`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d35b5a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 39s, sys: 19.9 ms, total: 3min 39s\n",
      "Wall time: 3min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_test = {'identities': [], 'filenames': []}\n",
    "\n",
    "for index, row in df_if.iterrows():\n",
    "    data_test['identities'].append(row['identity'])\n",
    "    temp_list = []\n",
    "    for filename in row['filenames']:\n",
    "        if filename not in seen_images:\n",
    "            temp_list.append(filename)\n",
    "    data_test['filenames'].append(json.dumps(temp_list))\n",
    "\n",
    "len(data_test['filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "2fe0ef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(data=data_test, columns=['identities', 'filenames'])\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd7e581",
   "metadata": {},
   "source": [
    "Dropping identities, who doesn't have any images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "deb0bfc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_drop = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    if len(row['filenames']) < 2:\n",
    "        rows_to_drop.append(row['identities'])\n",
    "\n",
    "len(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "39f5273a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_images = df_test.loc[~df_test['identities'].isin(rows_to_drop)]\n",
    "df_test_images.to_csv('test_identities_filenames.csv', index=False)\n",
    "len(df_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36e963",
   "metadata": {},
   "source": [
    "### 2.5 `df_test_encodings`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9defec8",
   "metadata": {},
   "source": [
    "Creating DataFrame, where each identity will have his list of face encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "4a7690dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 18min 34s, sys: 8.02 s, total: 2h 18min 42s\n",
      "Wall time: 2h 34min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_encodings, test_errors, test_seen_images, test_data = filenames_into_encodings(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20cbc0c",
   "metadata": {},
   "source": [
    "Saving the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "23076708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.2582927942276001, 0.08399071544408798, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.10332327336072922, 0.07786936312913895, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identities                                          encodings\n",
       "0        2880  [[-0.08185373246669769, 0.10833615064620972, -...\n",
       "1        2937  [[-0.08213772624731064, 0.0223865807056427, 0....\n",
       "2        8692  [[-0.03371645510196686, 0.10744943469762802, 0...\n",
       "3        5805  [[-0.2582927942276001, 0.08399071544408798, 0....\n",
       "4        9295  [[-0.10332327336072922, 0.07786936312913895, 0..."
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encodings = pd.DataFrame(data=test_data, columns=['identities', 'encodings'])\n",
    "df_test_encodings.to_csv('identities_encodings_test.csv', index=False)\n",
    "df_test_encodings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67754aeb",
   "metadata": {},
   "source": [
    "Reading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d772ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.2582927942276001, 0.08399071544408798, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.10332327336072922, 0.07786936312913895, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>5920</td>\n",
       "      <td>[[-0.18387816846370697, 0.0963742733001709, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>9268</td>\n",
       "      <td>[[-0.21787138283252716, 0.15073078870773315, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>8052</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>8146</td>\n",
       "      <td>[[-0.03438824787735939, 0.09196805953979492, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>9454</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings\n",
       "0           2880  [[-0.08185373246669769, 0.10833615064620972, -...\n",
       "1           2937  [[-0.08213772624731064, 0.0223865807056427, 0....\n",
       "2           8692  [[-0.03371645510196686, 0.10744943469762802, 0...\n",
       "3           5805  [[-0.2582927942276001, 0.08399071544408798, 0....\n",
       "4           9295  [[-0.10332327336072922, 0.07786936312913895, 0...\n",
       "...          ...                                                ...\n",
       "9338        5920  [[-0.18387816846370697, 0.0963742733001709, 0....\n",
       "9339        9268  [[-0.21787138283252716, 0.15073078870773315, 0...\n",
       "9340        8052                                                 []\n",
       "9341        8146  [[-0.03438824787735939, 0.09196805953979492, 0...\n",
       "9342        9454                                                 []\n",
       "\n",
       "[9343 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_read = pd.read_csv('identities_encodings_test.csv')\n",
    "df_test_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a86f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_identities_with_less_than_n_encodings(df: pd.DataFrame, n: int):\n",
    "    identities_to_drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        encodings_list = json.loads(row['encodings'])\n",
    "        if len(encodings_list) < n:\n",
    "            identities_to_drop.append(row['identities'])\n",
    "    return identities_to_drop\n",
    "\n",
    "\n",
    "def create_column_with_n_encodings(df: pd.DataFrame, n: int):\n",
    "    n_encodings = []\n",
    "    for index, row in df.iterrows():\n",
    "        encodings_list = json.loads(row['encodings'])\n",
    "        temp_encodings = []\n",
    "        counter = 0\n",
    "        for enc in encodings_list:\n",
    "            if counter < n:\n",
    "                temp_encodings.append(enc)\n",
    "                counter += 1\n",
    "        n_encodings.append(temp_encodings)\n",
    "    return n_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751267aa",
   "metadata": {},
   "source": [
    "Cleaning identities, who has less than 5 encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b129edcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8270"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_drop = find_identities_with_less_than_n_encodings(df_test_read, 5)\n",
    "df_test_read = df_test_read.loc[~df_test_read['identities'].isin(idx_to_drop)]\n",
    "len(df_test_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c3d4d",
   "metadata": {},
   "source": [
    "Creating new column, where is left only 5 encodings for each identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2de4f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5022/3506942747.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_read.loc[:, ('5_encodings')] = new_column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "      <th>5_encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.2582927942276001, 0.08399071544408798, 0....</td>\n",
       "      <td>[[-0.2582927942276001, 0.08399071544408798, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.10332327336072922, 0.07786936312913895, 0...</td>\n",
       "      <td>[[-0.10332327336072922, 0.07786936312913895, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>5013</td>\n",
       "      <td>[[-0.07761994749307632, 0.055308748036623, 0.1...</td>\n",
       "      <td>[[-0.07761994749307632, 0.055308748036623, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9331</th>\n",
       "      <td>9710</td>\n",
       "      <td>[[-0.111241415143013, 0.07181288301944733, 0.0...</td>\n",
       "      <td>[[-0.111241415143013, 0.07181288301944733, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9334</th>\n",
       "      <td>6258</td>\n",
       "      <td>[[-0.04995613917708397, 0.057822298258543015, ...</td>\n",
       "      <td>[[-0.04995613917708397, 0.057822298258543015, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9335</th>\n",
       "      <td>10101</td>\n",
       "      <td>[[-0.1197553351521492, 0.00509718619287014, 0....</td>\n",
       "      <td>[[-0.1197553351521492, 0.00509718619287014, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>5920</td>\n",
       "      <td>[[-0.18387816846370697, 0.0963742733001709, 0....</td>\n",
       "      <td>[[-0.18387816846370697, 0.0963742733001709, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8270 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings  \\\n",
       "0           2880  [[-0.08185373246669769, 0.10833615064620972, -...   \n",
       "1           2937  [[-0.08213772624731064, 0.0223865807056427, 0....   \n",
       "2           8692  [[-0.03371645510196686, 0.10744943469762802, 0...   \n",
       "3           5805  [[-0.2582927942276001, 0.08399071544408798, 0....   \n",
       "4           9295  [[-0.10332327336072922, 0.07786936312913895, 0...   \n",
       "...          ...                                                ...   \n",
       "9329        5013  [[-0.07761994749307632, 0.055308748036623, 0.1...   \n",
       "9331        9710  [[-0.111241415143013, 0.07181288301944733, 0.0...   \n",
       "9334        6258  [[-0.04995613917708397, 0.057822298258543015, ...   \n",
       "9335       10101  [[-0.1197553351521492, 0.00509718619287014, 0....   \n",
       "9338        5920  [[-0.18387816846370697, 0.0963742733001709, 0....   \n",
       "\n",
       "                                            5_encodings  \n",
       "0     [[-0.08185373246669769, 0.10833615064620972, -...  \n",
       "1     [[-0.08213772624731064, 0.0223865807056427, 0....  \n",
       "2     [[-0.03371645510196686, 0.10744943469762802, 0...  \n",
       "3     [[-0.2582927942276001, 0.08399071544408798, 0....  \n",
       "4     [[-0.10332327336072922, 0.07786936312913895, 0...  \n",
       "...                                                 ...  \n",
       "9329  [[-0.07761994749307632, 0.055308748036623, 0.1...  \n",
       "9331  [[-0.111241415143013, 0.07181288301944733, 0.0...  \n",
       "9334  [[-0.04995613917708397, 0.057822298258543015, ...  \n",
       "9335  [[-0.1197553351521492, 0.00509718619287014, 0....  \n",
       "9338  [[-0.18387816846370697, 0.0963742733001709, 0....  \n",
       "\n",
       "[8270 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column = create_column_with_n_encodings(df_test_read, 5)\n",
    "df_test_read.loc[:, ('5_encodings')] = new_column\n",
    "df_test_read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1647197f",
   "metadata": {},
   "source": [
    "# <a id=\"testing\">3. Testing perfomance of the different approaches</a>  \n",
    "## 3.1 Baseline  \n",
    "- Take the first encoding of each person\n",
    "- Choosing the best tolerance threshold\n",
    "- Maximize the accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06fa649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_encoding(encodings_list, encoding, np_ar, method):\n",
    "    \"\"\"\n",
    "        - Takes the list of all encodings, encoding which is going to be compared, \n",
    "            parameters for np.arange function, which will choose the threshold and method name\n",
    "        - Depends on method name proceeds different algorithm of comparing face encodings\n",
    "        - Returns a list of predicted identities. List length equals to amount of iterated thresholds\n",
    "        \n",
    "    \"\"\"\n",
    "    threshold_results = []\n",
    "    encodings_list = np.array(encodings_list)\n",
    "    encoding = np.array(encoding)\n",
    "    \n",
    "    \n",
    "    if method == 'distance_threshold':\n",
    "        results = face_recognition.face_distance(encodings_list, encoding)\n",
    "        batch_size = 5\n",
    "        for threshold in np.arange(np_ar[0], np_ar[1], np_ar[2]):\n",
    "            matched_identity_idx = None\n",
    "            for i in range(0, len(results), batch_size):\n",
    "                mean_distance = np.mean(results[i:i+batch_size])\n",
    "                if mean_distance < threshold:\n",
    "                    matched_identity_idx = i // 5\n",
    "                    break\n",
    "            if matched_identity_idx is None:\n",
    "                threshold_results.append(None)\n",
    "            else:\n",
    "                identity_actual = users[matched_identity_idx]\n",
    "                threshold_results.append(identity_actual)    \n",
    "            \n",
    "            \n",
    "    elif method == 'min_distance':        \n",
    "        results = face_recognition.face_distance(encodings_list, encoding)\n",
    "        batch_size = 5\n",
    "        distances = []\n",
    "        for i in range(0, len(results), batch_size):\n",
    "            mean_distance = np.mean(results[i:i+batch_size])\n",
    "            distances.append(mean_distance)\n",
    "        matched_identity_idx = distances.index(np.min(distances))\n",
    "        identity_actual = users[matched_identity_idx]\n",
    "        threshold_results.append(identity_actual)\n",
    "    \n",
    "    \n",
    "    else:        \n",
    "        for i in np.arange(np_ar[0], np_ar[1], np_ar[2]):\n",
    "            results = face_recognition.compare_faces(encodings_list, encoding, tolerance=i)\n",
    "            if True in results:\n",
    "                if method == '5inarow':\n",
    "                    batch_size = 5\n",
    "                    matched_identity_idx = None\n",
    "                    truth_list = []\n",
    "                    for index in range(0, len(results), batch_size):\n",
    "                        true_num = results[index:index+batch_size].count(True)\n",
    "                        truth_list.append(true_num)\n",
    "#                         if true_num == 5:\n",
    "#                             matched_identity_idx = index // 5\n",
    "#                             break\n",
    "                    matched_identity_idx = truth_list.index(max(truth_list))\n",
    "                            \n",
    "                    if matched_identity_idx is None:\n",
    "                        threshold_results.append(None)\n",
    "                        \n",
    "                    else:\n",
    "                        identity_actual = users[matched_identity_idx]\n",
    "                        threshold_results.append(identity_actual)\n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                    matched_identity_idx = results.index(True)\n",
    "                    identity_actual = users[matched_identity_idx]\n",
    "                    threshold_results.append(identity_actual)\n",
    "            else:\n",
    "                threshold_results.append(None)\n",
    "    \n",
    "    \n",
    "    return threshold_results \n",
    "\n",
    "\n",
    "def calc_acc(array: list, true_value: int):\n",
    "    \"\"\"\n",
    "        - Takes array of predictions and a `true_value`\n",
    "        - Compares and counts accuracy\n",
    "        - Returns accuracy for a list\n",
    "    \"\"\"\n",
    "    right_preds = 0\n",
    "    for el in array:\n",
    "        if el == true_value:\n",
    "            right_preds += 1\n",
    "    accuracy = right_preds / len(array)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_predictions(row, encodings_list, np_ar, method: str, limit: int = 5) -> list:\n",
    "    \"\"\"\n",
    "        - Takes a row of `df_test_encodings` DataFrame\n",
    "        - Goes into a for loop for each encoding and matches it to `encodings` list\n",
    "        - Calls `match_encoding` function\n",
    "    \"\"\"\n",
    "    predictions_for_each_image = []    \n",
    "    for encoding in row['5_encodings']:\n",
    "        results = match_encoding(encodings_list, encoding, np_ar, method)    \n",
    "            \n",
    "        if results is None:\n",
    "            continue        \n",
    "        predictions_for_each_image.append(results)  \n",
    "    return predictions_for_each_image\n",
    "\n",
    "        \n",
    "def get_accuracy_by_threshold(row, results_by_threshold):\n",
    "    \"\"\"\n",
    "        - Takes the dict from `get_results_by_threshold`\n",
    "        - Calculates accuracy for each threshold\n",
    "        - Return accuracies list\n",
    "    \"\"\"\n",
    "    acc_by_threshold = []\n",
    "    for key in results_by_threshold:\n",
    "        acc = calc_acc(results_by_threshold[key], row['identities'])\n",
    "        acc_by_threshold.append(acc)  \n",
    "    return acc_by_threshold\n",
    "\n",
    "\n",
    "def get_accuracy(row, predictions, np_ar, method):\n",
    "    \"\"\"\n",
    "        - Takes the dict from `get_results_by_threshold`\n",
    "        - Calculates accuracy for each threshold\n",
    "        - Return accuracies list\n",
    "    \"\"\"\n",
    "    acc_by_threshold = []\n",
    "    if method == 'min_distance':\n",
    "        acc = calc_acc(predictions[:, 0], row['identities'])\n",
    "        acc_by_threshold.append(acc) \n",
    "    else:\n",
    "        length = len(np.arange(np_ar[0], np_ar[1], np_ar[2]))\n",
    "        for i in range(length):\n",
    "            acc = calc_acc(predictions[:, i], row['identities'])\n",
    "            acc_by_threshold.append(acc)  \n",
    "    return acc_by_threshold\n",
    "\n",
    "\n",
    "def create_accuracy_column(df, encodings_list, np_ar, method: str):\n",
    "    \"\"\"\n",
    "        - Takes `df_test` DataFrame\n",
    "        - Calls `get_predictions`, `get_results_by_threshold`, `get_accuracy_by_threshold`\n",
    "        - Returns list of lists (for each person) with accuracies (for each tolerance threshold)\n",
    "    \"\"\"\n",
    "    accuracy_list = [] \n",
    "    for index, row in df.iloc[8000:8200].iterrows():\n",
    "#     for index, row in df.iterrows():\n",
    "        predictions_for_each_image = get_predictions(row, encodings_list, np_ar, method)        \n",
    "        predictions = np.array(predictions_for_each_image)\n",
    "#         print(predictions)\n",
    "        acc_by_threshold = get_accuracy(row, predictions, np_ar, method)\n",
    "        accuracy_list.append(acc_by_threshold)\n",
    "        \n",
    "    return accuracy_list\n",
    "\n",
    "\n",
    "def print_acc_by_threshold(accuracies, np_ar):\n",
    "    accuracies = np.array(accuracies)\n",
    "    \n",
    "    for i, threshold in enumerate(np.arange(np_ar[0], np_ar[1], np_ar[2])):\n",
    "        print(f'Accuracy with {threshold:.3f} threshold: {accuracies[:, i].mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61a38b7",
   "metadata": {},
   "source": [
    "### Measuring accuracy for the Baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d507a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_1_per_person = encodings[::5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21174376",
   "metadata": {},
   "source": [
    "Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f74fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "identities_accuracies_053_06 = create_accuracy_column(df_test_read, encodings_1_per_person, np_ar=(0.53, 0.601, 0.01), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d246aeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc_by_threshold(identities_accuracies_053_06, (0.53, 0.601, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471b95c",
   "metadata": {},
   "source": [
    "#### The biggest accuracy was achieved with the threshold of 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07da89e",
   "metadata": {},
   "source": [
    "## 3.2 Mean Encoding  \n",
    "- Create one mean encoding from five given encodings for each person\n",
    "- Choose the best tolerance threshold\n",
    "- Maximize the accuracy metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dda92cb",
   "metadata": {},
   "source": [
    "#### Creating mean encodigns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36794a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9283"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "mean_encodings = []\n",
    "batch_size = 5\n",
    "\n",
    "for i in range(0, len(encodings), batch_size):\n",
    "    mean_enc = np.mean(encodings[i:i+batch_size])\n",
    "    mean_encodings.append(mean_enc)\n",
    "\n",
    "len(mean_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e972f696",
   "metadata": {},
   "source": [
    "Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "c37f2c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 30min 16s, sys: 49min 22s, total: 5h 19min 39s\n",
      "Wall time: 5h 19min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_3_0_5 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.3, 0.501, 0.01), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "ca5fa2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.300 threshold: 0.15\n",
      "Accuracy with 0.310 threshold: 0.19\n",
      "Accuracy with 0.320 threshold: 0.24\n",
      "Accuracy with 0.330 threshold: 0.29\n",
      "Accuracy with 0.340 threshold: 0.34\n",
      "Accuracy with 0.350 threshold: 0.40\n",
      "Accuracy with 0.360 threshold: 0.46\n",
      "Accuracy with 0.370 threshold: 0.51\n",
      "Accuracy with 0.380 threshold: 0.56\n",
      "Accuracy with 0.390 threshold: 0.61\n",
      "Accuracy with 0.400 threshold: 0.65\n",
      "Accuracy with 0.410 threshold: 0.69\n",
      "Accuracy with 0.420 threshold: 0.72\n",
      "Accuracy with 0.430 threshold: 0.74\n",
      "Accuracy with 0.440 threshold: 0.74\n",
      "Accuracy with 0.450 threshold: 0.73\n",
      "Accuracy with 0.460 threshold: 0.71\n",
      "Accuracy with 0.470 threshold: 0.65\n",
      "Accuracy with 0.480 threshold: 0.58\n",
      "Accuracy with 0.490 threshold: 0.49\n",
      "Accuracy with 0.500 threshold: 0.39\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_3_0_5, (0.3, 0.501, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c714d39",
   "metadata": {},
   "source": [
    "#### The best accuracy with this method was get with 0.43 threshold and equals 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dabca7e",
   "metadata": {},
   "source": [
    "## 3.3 Minimum accordance amount\n",
    "- After getting a result from `compare_faces` function, look for 3, 4, 5 True values in a row and return the prediction  \n",
    "- Choose the best `min_accordance` value (3-5)  \n",
    "- Choose the best tolerance threshold  \n",
    "- Maximize the accuracy metric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "45467c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 27s, sys: 31.4 s, total: 5min 59s\n",
      "Wall time: 5min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_5inarow_048_056 = create_accuracy_column(df_test_read, encodings, np_ar=(0.48, 0.561, 0.01), method='5inarow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "4a319c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.480 threshold: 0.77\n",
      "Accuracy with 0.490 threshold: 0.76\n",
      "Accuracy with 0.500 threshold: 0.76\n",
      "Accuracy with 0.510 threshold: 0.76\n",
      "Accuracy with 0.520 threshold: 0.75\n",
      "Accuracy with 0.530 threshold: 0.76\n",
      "Accuracy with 0.540 threshold: 0.76\n",
      "Accuracy with 0.550 threshold: 0.72\n",
      "Accuracy with 0.560 threshold: 0.70\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_5inarow_048_056, (0.48, 0.561, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2686cb6",
   "metadata": {},
   "source": [
    "#### Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "4722c839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 34s, sys: 1min 29s, total: 14min 4s\n",
      "Wall time: 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_5inarow_03_056 = create_accuracy_column(df_test_read, encodings, np_ar=(0.3, 0.561, 0.01), method='5inarow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "id": "81e1036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.300 threshold: 0.06\n",
      "Accuracy with 0.310 threshold: 0.10\n",
      "Accuracy with 0.320 threshold: 0.10\n",
      "Accuracy with 0.330 threshold: 0.15\n",
      "Accuracy with 0.340 threshold: 0.21\n",
      "Accuracy with 0.350 threshold: 0.25\n",
      "Accuracy with 0.360 threshold: 0.30\n",
      "Accuracy with 0.370 threshold: 0.37\n",
      "Accuracy with 0.380 threshold: 0.44\n",
      "Accuracy with 0.390 threshold: 0.49\n",
      "Accuracy with 0.400 threshold: 0.53\n",
      "Accuracy with 0.410 threshold: 0.59\n",
      "Accuracy with 0.420 threshold: 0.63\n",
      "Accuracy with 0.430 threshold: 0.68\n",
      "Accuracy with 0.440 threshold: 0.71\n",
      "Accuracy with 0.450 threshold: 0.74\n",
      "Accuracy with 0.460 threshold: 0.76\n",
      "Accuracy with 0.470 threshold: 0.76\n",
      "Accuracy with 0.480 threshold: 0.77\n",
      "Accuracy with 0.490 threshold: 0.76\n",
      "Accuracy with 0.500 threshold: 0.76\n",
      "Accuracy with 0.510 threshold: 0.76\n",
      "Accuracy with 0.520 threshold: 0.75\n",
      "Accuracy with 0.530 threshold: 0.76\n",
      "Accuracy with 0.540 threshold: 0.76\n",
      "Accuracy with 0.550 threshold: 0.72\n",
      "Accuracy with 0.560 threshold: 0.70\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_5inarow_03_056, (0.3, 0.561, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa212fb5",
   "metadata": {},
   "source": [
    "## 3.4 Face distance  \n",
    "- Use `face_distance` instead of compare faces  \n",
    "- Calculate overall distance by 5 encodings for each person \n",
    "- Choosing the first value, which is lower than the threshold and the corresponding person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "334a5b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 4s, sys: 5.59 s, total: 4min 9s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ident_accs_dist_thresh_048_055 = create_accuracy_column(df_test_read, encodings, np_ar=(0.48, 0.551, 0.01), method='distance_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "eef912d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.380 threshold: 0.52\n",
      "Accuracy with 0.390 threshold: 0.57\n",
      "Accuracy with 0.400 threshold: 0.61\n",
      "Accuracy with 0.410 threshold: 0.62\n",
      "Accuracy with 0.420 threshold: 0.62\n",
      "Accuracy with 0.430 threshold: 0.65\n",
      "Accuracy with 0.440 threshold: 0.63\n",
      "Accuracy with 0.450 threshold: 0.57\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(ident_accs_dist_thresh_048_055, (0.38, 0.451, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529c8f9",
   "metadata": {},
   "source": [
    "#### Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "id": "2a016645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 4s, sys: 5.06 s, total: 4min 9s\n",
      "Wall time: 4min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ident_accs_dist_thresh_039_045 = create_accuracy_column(df_test_read, encodings, np_ar=(0.39, 0.451, 0.01), method='distance_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "id": "67f4d3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.390 threshold: 0.12\n",
      "Accuracy with 0.400 threshold: 0.15\n",
      "Accuracy with 0.410 threshold: 0.20\n",
      "Accuracy with 0.420 threshold: 0.24\n",
      "Accuracy with 0.430 threshold: 0.28\n",
      "Accuracy with 0.440 threshold: 0.35\n",
      "Accuracy with 0.450 threshold: 0.40\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(ident_accs_dist_thresh_039_045, (0.39, 0.451, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b46702e",
   "metadata": {},
   "source": [
    "## 3.5 Minimum face distance  \n",
    "- Use `face_distance` instead of compare faces  \n",
    "- Calculate overall distance by 5 encodings for each person \n",
    "- Choosing the lowest value and the corresponding person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "9b1415ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 59min 13s, sys: 13min 51s, total: 6h 13min 5s\n",
      "Wall time: 6h 13min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ident_accs_min_dist = create_accuracy_column(df_test_read, encodings, np_ar=(0.38, 0.451, 0.01), method='min_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "e55760bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "print(f'{np.mean(ident_accs_min_dist):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63d76a",
   "metadata": {},
   "source": [
    "Distribution of accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "a151b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0]    4940\n",
       "[0.8]    1795\n",
       "[0.6]     726\n",
       "[0.4]     360\n",
       "[0.0]     249\n",
       "[0.2]     200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ident_accs_min_dist).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "6c510b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129607291247822"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.Series(ident_accs_min_dist).apply(lambda x: x[0])\n",
    "np.mean(res.loc[res > 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "02bab49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7461"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.loc[res > 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388bb0ee",
   "metadata": {},
   "source": [
    "# <a id=\"conclusion\">4. Conclusions</a>  \n",
    "At the end of the data preparation, we've left with the `df_final` and `encodings` list both include **9283 unique identities**. It can be considered as the complexity of the system because the more registered people we have in a database the easier algorithm can mismatch the face.  \n",
    "  \n",
    "While testing a few different approaches to face comparison, I was using `df_test_encodings`, which includes **8270 identities** and each identity has 5 encodings, so in total each test contained **41350 face encodings**. The DataFrame contains fewer identities than `df_final` due to the number of images and their quality. Some images were 'damaged', which means that on such images `face_locations` method couldn't find a face.  \n",
    "  \n",
    "The best accuracy was measured with the last comparison algorithm. It was calculating Euclidean distances to each encoding, got the mean distance for each identity from the dataset, and returned the identity with the least distance value. The final accuracy was 85%  \n",
    "  \n",
    "The accuracy can be more than 90% if the dataset is more accurate. For example, on the final distribution of the results, we can find 450 identities with 0-20% accuracy. Such accuracy means that zero or only one out of 5 checked test face encodings was evenly close to the corresponding identity. There can be many causes of such accuracy, but I think, a big impact was made by the quality of the images. They were just downloaded from the internet. The faces were captured under different lighting, angles, AOV, etc.\n",
    "  \n",
    "In the project, we can easily retake 5 photos and the overall accuracy will increase. Actually, if we take all photos qualitatively from the beginning, the algorithm's accuracy will be much higher."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9_face_recognition",
   "language": "python",
   "name": "python3.9_face_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
