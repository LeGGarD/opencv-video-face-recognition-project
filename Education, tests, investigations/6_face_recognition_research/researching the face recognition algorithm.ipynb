{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fec18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af185957",
   "metadata": {},
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69c66ab",
   "metadata": {},
   "source": [
    "### identity_CelebA dataframe\n",
    "here we have only `filename` column and corresponding `identity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971be343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  identity\n",
       "0  000001.jpg      2880\n",
       "1  000002.jpg      2937\n",
       "2  000003.jpg      8692"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading dataset 'identity_CelebA'\n",
    "df_identity = pd.read_csv('dataset/identity_CelebA.txt', sep=' ', names=['filename', 'identity'])\n",
    "df_identity.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bfaec2",
   "metadata": {},
   "source": [
    "leaving only those identities, who have more than 7 photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "fd51a180",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution = df_identity['identity'].value_counts()  # counting how many images there are for each identity\n",
    "distr = distribution.loc[distribution > 4]             # leaving identities, who has 7+ images \n",
    "idx_list = distr.index                                 # getting indexes of the left identities\n",
    "len(idx_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bfca48",
   "metadata": {},
   "source": [
    "### Creating the DataFrame, where each row is the identity index and the corresponding filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "50a353c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_identities_dict(row):\n",
    "    if row['identity'] in identities_dict:\n",
    "        identities_dict[row['identity']][0].append(row['filename'])\n",
    "    else:\n",
    "        identities_dict[row['identity']] = [[row['filename']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d3f3bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 7.99 ms, total: 12.3 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_dict = {}\n",
    "\n",
    "for index, row in df_identity.iterrows():\n",
    "    create_identities_dict(row)\n",
    "\n",
    "# creating identities/filenames DataFrame\n",
    "df_if = pd.DataFrame.from_dict(identities_dict, orient='index').reset_index().rename(columns={\"index\": 'identities', 0: 'filenames'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "17e8ff60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame has 9343 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity</th>\n",
       "      <th>filenames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[000001.jpg, 000404.jpg, 003415.jpg, 004390.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[000002.jpg, 011437.jpg, 016335.jpg, 017121.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[000003.jpg, 015648.jpg, 033840.jpg, 038887.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[000004.jpg, 001778.jpg, 010191.jpg, 013676.jp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[000005.jpg, 008431.jpg, 014427.jpg, 016680.jp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identity                                          filenames\n",
       "0      2880  [000001.jpg, 000404.jpg, 003415.jpg, 004390.jp...\n",
       "1      2937  [000002.jpg, 011437.jpg, 016335.jpg, 017121.jp...\n",
       "2      8692  [000003.jpg, 015648.jpg, 033840.jpg, 038887.jp...\n",
       "3      5805  [000004.jpg, 001778.jpg, 010191.jpg, 013676.jp...\n",
       "4      9295  [000005.jpg, 008431.jpg, 014427.jpg, 016680.jp..."
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_if = df_if.loc[df_if['identities'].isin(idx_list)]\n",
    "print('DataFrame has ' + str(len(df_if)) + ' rows')\n",
    "df_if.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b698f",
   "metadata": {},
   "source": [
    "# 2. Creating data structures for face recognition algorithm\n",
    "We need:  \n",
    "`df_final` - a DataFrame where each identity has 5 face encodings  \n",
    "`encodings` - array of all encodings  \n",
    "`users` - dictionary, where keys are users' idx and the values are the corresponding names/addresses (here these are identities' idx, but in my project it will change)  \n",
    "`df_test_images` - DataFrame with the images that weren't parsed into encodings earlier  \n",
    "`df_test_encodings` - DataFrame with identities and images parsed into encodings  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32071ff",
   "metadata": {},
   "source": [
    "### 2.1 `df_final`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8ad35891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_encodings(filename):\n",
    "    \"\"\"\n",
    "        - Gets filename, reads the image, finds faces, creates face encodings\n",
    "        - Returns face encoding, if a face was found on the image\n",
    "    \"\"\"\n",
    "    img = cv2.imread('dataset/img_align_celeba/' + filename)\n",
    "    locations = face_recognition.face_locations(img, model='hog')\n",
    "    encodings_ = face_recognition.face_encodings(img, locations)\n",
    "    return encodings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ae7b95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_new_image(identity, filenames_list):\n",
    "    \"\"\"\n",
    "        - Gets id of identity and list of filenames, which belongs to identity\n",
    "        - Proceeds a search of non-seen images and trying to recognize face on it\n",
    "        - Goes into recursion, if a face wasn't found\n",
    "        - Returns face encoding and filename of the image, on which the face was recognized\n",
    "    \"\"\"\n",
    "    global seen_images\n",
    "    for filename_ in filenames_list:\n",
    "        if filename_ not in seen_images:\n",
    "            encodings_ = image_to_encodings(filename_)\n",
    "            seen_images.append(filename_)\n",
    "            filenames_list.remove(filename_)\n",
    "            if len(encodings_) != 1:\n",
    "                new_encoding_, new_filename_ = find_new_image(identity, filenames_list)\n",
    "                seen_images.append(new_filename_)\n",
    "                return new_encoding_, new_filename_\n",
    "            return encodings_[0], filename_\n",
    "    return None, None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "f6267535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filenames_into_encodings(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "        - Takes a DataFrame with columns 'filenames' and 'identities'\n",
    "        - Reads each image, creates face encodings, tries to find new image in case the face wasn't found \n",
    "        or skips damaged images/identities\n",
    "        - Returns:\n",
    "            - `encodings_overall` - list with all encodings\n",
    "            - `errors` - log of images, on which there was 0 or more than 1 faces\n",
    "            - `seen_images_` - list of seen images\n",
    "            - `data_` - dictionary, where keys are identities idx and values are list of 5 face encodings\n",
    "    \"\"\"\n",
    "    encodings_overall = []  # list of all encodings \n",
    "    errors_ = []  # list for images, where weren't located any faces\n",
    "    seen_images_ = []\n",
    "    data_ = {'identities': [], 'encodings': []}\n",
    "\n",
    "    # for identity in df['identity'].iloc[:100].values:\n",
    "    # be careful with the activation of the line below, it takes almost 2 hours to proceed\n",
    "    for identity in df['identities'].values:\n",
    "#         filenames_list = df['filenames'].loc[df['identities'] == identity].values[0]\n",
    "        filenames_list = json.loads(df['filenames'].loc[df['identities'] == identity].values[0])\n",
    "        counter = 0\n",
    "        data_['identities'].append(identity)\n",
    "        temp_encodings = []\n",
    "        for filename in filenames_list:\n",
    "            if counter >= 5:\n",
    "                continue\n",
    "\n",
    "            encodings_ = image_to_encodings(filename)\n",
    "            seen_images_.append(filename)\n",
    "\n",
    "            # if a face wasn't found or there were more than 1 face\n",
    "            if len(encodings_) != 1:\n",
    "                # try to find another image of the same identity\n",
    "                new_encoding, new_filename = find_new_image(identity, filenames_list)\n",
    "\n",
    "                # if there wasn't any other photos\n",
    "                if new_encoding is None:\n",
    "                    # append an error message\n",
    "                    errors_.append(('problem in:', filename, new_filename, identity, 'solved with:', 'ISN\\'T SOLVED'))\n",
    "                else:\n",
    "                    encodings_overall.append(new_encoding)\n",
    "                    temp_encodings.append(list(new_encoding))\n",
    "                    errors_.append(('problem in:', filename, identity, 'solved with:', new_filename))\n",
    "            else:\n",
    "                encodings_overall.append(encodings_[0])\n",
    "                temp_encodings.append(list(encodings_[0]))\n",
    "\n",
    "            counter += 1\n",
    "        data_['encodings'].append(json.dumps(temp_encodings))\n",
    "    return encodings_overall, errors_, seen_images_, data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aad3a013",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 28min, sys: 7.35 s, total: 2h 28min 8s\n",
      "Wall time: 2h 35min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encodings, errors, seen_images, data = filenames_into_encodings(df_if)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c88d1b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48567"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seen_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daeedf1",
   "metadata": {},
   "source": [
    "Creating and saving the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "006a2cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.09392920881509781, 0.16680526733398438, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.13565079867839813, 0.04019104316830635, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.08772975206375122, 0.17790649831295013, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.207429900765419, 0.17357361316680908, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.11555222421884537, 0.05275091528892517, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identities                                          encodings\n",
       "0        2880  [[-0.09392920881509781, 0.16680526733398438, 0...\n",
       "1        2937  [[-0.13565079867839813, 0.04019104316830635, 0...\n",
       "2        8692  [[-0.08772975206375122, 0.17790649831295013, 0...\n",
       "3        5805  [[-0.207429900765419, 0.17357361316680908, -0....\n",
       "4        9295  [[-0.11555222421884537, 0.05275091528892517, 0..."
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = pd.DataFrame(data=data, columns=['identities', 'encodings'])\n",
    "df_fin.to_csv('identities_encodings_super_final.csv', index=False)\n",
    "df_fin.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc8a2a",
   "metadata": {},
   "source": [
    "Reading the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "963d0dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.09392920881509781, 0.16680526733398438, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.13565079867839813, 0.04019104316830635, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.08772975206375122, 0.17790649831295013, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.207429900765419, 0.17357361316680908, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.11555222421884537, 0.05275091528892517, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>5920</td>\n",
       "      <td>[[-0.20153068006038666, 0.13730086386203766, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>9268</td>\n",
       "      <td>[[-0.10642589628696442, 0.13724175095558167, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>8052</td>\n",
       "      <td>[[0.06224041059613228, 0.005616001784801483, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>8146</td>\n",
       "      <td>[[-0.12671472132205963, 0.1192317008972168, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>9454</td>\n",
       "      <td>[[-0.030202826485037804, 0.10130798816680908, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings\n",
       "0           2880  [[-0.09392920881509781, 0.16680526733398438, 0...\n",
       "1           2937  [[-0.13565079867839813, 0.04019104316830635, 0...\n",
       "2           8692  [[-0.08772975206375122, 0.17790649831295013, 0...\n",
       "3           5805  [[-0.207429900765419, 0.17357361316680908, -0....\n",
       "4           9295  [[-0.11555222421884537, 0.05275091528892517, 0...\n",
       "...          ...                                                ...\n",
       "9338        5920  [[-0.20153068006038666, 0.13730086386203766, 0...\n",
       "9339        9268  [[-0.10642589628696442, 0.13724175095558167, 0...\n",
       "9340        8052  [[0.06224041059613228, 0.005616001784801483, -...\n",
       "9341        8146  [[-0.12671472132205963, 0.1192317008972168, 0....\n",
       "9342        9454  [[-0.030202826485037804, 0.10130798816680908, ...\n",
       "\n",
       "[9343 rows x 2 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_fin = pd.read_csv('identities_encodings_super_final.csv')\n",
    "df_read_fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4db7b6",
   "metadata": {},
   "source": [
    "Checking how many face encodings each person has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e857b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_enc_quant(row):\n",
    "    if len(json.loads(row['encodings'])) != 5:\n",
    "        damaged_rows.append(row['identities'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91043efc",
   "metadata": {},
   "source": [
    "Finding the damaged rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "e1d39113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damaged_rows = []\n",
    "\n",
    "for index, row in df_read_fin.iterrows():\n",
    "    check_enc_quant(row)\n",
    "    \n",
    "len(damaged_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cbd292",
   "metadata": {},
   "source": [
    "Dropping the damaged rows and saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "86464eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9283"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_fin = df_read_fin.loc[~df_read_fin['identities'].isin(damaged_rows)]\n",
    "df_read_fin.to_csv('identities_encodings_super_final2.csv', index=False)\n",
    "len(df_read_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead595d9",
   "metadata": {},
   "source": [
    "### 2.2 `encodings`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7110d0",
   "metadata": {},
   "source": [
    "Reading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "da64759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9283 unique identities in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_csv('identities_encodings_super_final2.csv')\n",
    "print(f'{len(df_final)} unique identities in the DataFrame')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474c4c0",
   "metadata": {},
   "source": [
    "Creating list of all encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d1f03b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46415 face encodings in the encodings list\n"
     ]
    }
   ],
   "source": [
    "encodings = []\n",
    "for index, row in df_final.iterrows():\n",
    "    encodings.extend(json.loads(row['encodings']))\n",
    "\n",
    "print(f'{len(encodings)} face encodings in the encodings list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb90cd66",
   "metadata": {},
   "source": [
    "### 2.3 `users`:  \n",
    "Creating map:  \n",
    "- from encoding index // 5   \n",
    "- to identity or user's name/address  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "7c312d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx = df_final['identities']\n",
    "users = {key: value for key, value in zip(range(len(user_idx)), user_idx)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe48e7f",
   "metadata": {},
   "source": [
    "### 2.4 `df_test_images`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999341f3",
   "metadata": {},
   "source": [
    "Creating new DataFrame, which consists of images, which weren't seen during creation of the main dataset (`df_final`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "923ff156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 39s, sys: 19.9 ms, total: 3min 39s\n",
      "Wall time: 3min 39s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "data_test = {'identities': [], 'filenames': []}\n",
    "\n",
    "for index, row in df_if.iterrows():\n",
    "    data_test['identities'].append(row['identity'])\n",
    "    temp_list = []\n",
    "    for filename in row['filenames']:\n",
    "        if filename not in seen_images:\n",
    "            temp_list.append(filename)\n",
    "    data_test['filenames'].append(json.dumps(temp_list))\n",
    "\n",
    "len(data_test['filenames'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "70713274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(data=data_test, columns=['identities', 'filenames'])\n",
    "len(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11599d8a",
   "metadata": {},
   "source": [
    "Dropping identities, who doesn't have any images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "35e0adeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_to_drop = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    if len(row['filenames']) < 2:\n",
    "        rows_to_drop.append(row['identities'])\n",
    "\n",
    "len(rows_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d688a65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9343"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_images = df_test.loc[~df_test['identities'].isin(rows_to_drop)]\n",
    "df_test_images.to_csv('test_identities_filenames.csv', index=False)\n",
    "len(df_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cedee1",
   "metadata": {},
   "source": [
    "### 2.5 `df_test_encodings`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ca0b2",
   "metadata": {},
   "source": [
    "Creating DataFrame, where each identity will have his list of face encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "3ab4b099",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 18min 34s, sys: 8.02 s, total: 2h 18min 42s\n",
      "Wall time: 2h 34min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_encodings, test_errors, test_seen_images, test_data = filenames_into_encodings(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1314dc2d",
   "metadata": {},
   "source": [
    "Saving the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "956d93b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.2582927942276001, 0.08399071544408798, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.10332327336072922, 0.07786936312913895, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identities                                          encodings\n",
       "0        2880  [[-0.08185373246669769, 0.10833615064620972, -...\n",
       "1        2937  [[-0.08213772624731064, 0.0223865807056427, 0....\n",
       "2        8692  [[-0.03371645510196686, 0.10744943469762802, 0...\n",
       "3        5805  [[-0.2582927942276001, 0.08399071544408798, 0....\n",
       "4        9295  [[-0.10332327336072922, 0.07786936312913895, 0..."
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_encodings = pd.DataFrame(data=test_data, columns=['identities', 'encodings'])\n",
    "df_test_encodings.to_csv('identities_encodings_test.csv', index=False)\n",
    "df_test_encodings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e866a7",
   "metadata": {},
   "source": [
    "Reading the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "dfe60a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.2582927942276001, 0.08399071544408798, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.10332327336072922, 0.07786936312913895, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>5920</td>\n",
       "      <td>[[-0.18387816846370697, 0.0963742733001709, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9339</th>\n",
       "      <td>9268</td>\n",
       "      <td>[[-0.21787138283252716, 0.15073078870773315, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9340</th>\n",
       "      <td>8052</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>8146</td>\n",
       "      <td>[[-0.03438824787735939, 0.09196805953979492, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9342</th>\n",
       "      <td>9454</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9343 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings\n",
       "0           2880  [[-0.08185373246669769, 0.10833615064620972, -...\n",
       "1           2937  [[-0.08213772624731064, 0.0223865807056427, 0....\n",
       "2           8692  [[-0.03371645510196686, 0.10744943469762802, 0...\n",
       "3           5805  [[-0.2582927942276001, 0.08399071544408798, 0....\n",
       "4           9295  [[-0.10332327336072922, 0.07786936312913895, 0...\n",
       "...          ...                                                ...\n",
       "9338        5920  [[-0.18387816846370697, 0.0963742733001709, 0....\n",
       "9339        9268  [[-0.21787138283252716, 0.15073078870773315, 0...\n",
       "9340        8052                                                 []\n",
       "9341        8146  [[-0.03438824787735939, 0.09196805953979492, 0...\n",
       "9342        9454                                                 []\n",
       "\n",
       "[9343 rows x 2 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_read = pd.read_csv('identities_encodings_test.csv')\n",
    "df_test_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2405de40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_identities_with_less_than_n_encodings(df: pd.DataFrame, n: int):\n",
    "    identities_to_drop = []\n",
    "    for index, row in df.iterrows():\n",
    "        encodings_list = json.loads(row['encodings'])\n",
    "        if len(encodings_list) < n:\n",
    "            identities_to_drop.append(row['identities'])\n",
    "    return identities_to_drop\n",
    "\n",
    "\n",
    "def create_column_with_n_encodings(df: pd.DataFrame, n: int):\n",
    "    n_encodings = []\n",
    "    for index, row in df.iterrows():\n",
    "        encodings_list = json.loads(row['encodings'])\n",
    "        temp_encodings = []\n",
    "        counter = 0\n",
    "        for enc in encodings_list:\n",
    "            if counter < n:\n",
    "                temp_encodings.append(enc)\n",
    "                counter += 1\n",
    "        n_encodings.append(temp_encodings)\n",
    "    return n_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a410c18",
   "metadata": {},
   "source": [
    "Cleaning identities, who has less than 5 encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "0523ad08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8270"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_drop = find_identities_with_less_than_n_encodings(df_test_read, 5)\n",
    "df_test_read = df_test_read.loc[~df_test_read['identities'].isin(idx_to_drop)]\n",
    "len(df_test_read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de998d",
   "metadata": {},
   "source": [
    "Creating new column, where is left only 5 encodings for each identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a58b9540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4710/3922244095.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test_read.loc[:, ('5_encodings')] = new_column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "      <th>5_encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "      <td>[[-0.08185373246669769, 0.10833615064620972, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "      <td>[[-0.08213772624731064, 0.0223865807056427, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "      <td>[[-0.03371645510196686, 0.10744943469762802, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identities                                          encodings  \\\n",
       "0        2880  [[-0.08185373246669769, 0.10833615064620972, -...   \n",
       "1        2937  [[-0.08213772624731064, 0.0223865807056427, 0....   \n",
       "2        8692  [[-0.03371645510196686, 0.10744943469762802, 0...   \n",
       "\n",
       "                                         5_encodings  \n",
       "0  [[-0.08185373246669769, 0.10833615064620972, -...  \n",
       "1  [[-0.08213772624731064, 0.0223865807056427, 0....  \n",
       "2  [[-0.03371645510196686, 0.10744943469762802, 0...  "
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_column = create_column_with_n_encodings(df_test_read, 5)\n",
    "df_test_read.loc[:, ('5_encodings')] = new_column\n",
    "df_test_read.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44303a71",
   "metadata": {},
   "source": [
    "# 3. Testing perfomance of the different approaches  \n",
    "## 3.1 Baseline  \n",
    "- Take the first encoding of each person\n",
    "- Choosing the best tolerance threshold\n",
    "- Maximize the accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "80d97996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_encoding(encodings_list, encoding, np_ar, method):\n",
    "    \"\"\"\n",
    "        - Takes the list of all encodings, encoding which is going to be compared, \n",
    "            parameters for np.arange function, which will choose the threshold and method name\n",
    "        - Depends on method name proceeds different algorithm of comparing face encodings\n",
    "        - Returns a list of predicted identities. List length equals to amount of iterated thresholds\n",
    "        \n",
    "    \"\"\"\n",
    "    threshold_results = []\n",
    "    encodings_list = np.array(encodings_list)\n",
    "    encoding = np.array(encoding)\n",
    "    \n",
    "    \n",
    "    if method == 'distance_threshold':\n",
    "        results = face_recognition.face_distance(encodings_list, encoding)\n",
    "        if True in results:\n",
    "            print('zaebok')\n",
    "            batch_size = 5\n",
    "            for threshold in np.arange(np_ar[0], np_ar[1], np_ar[2]):\n",
    "                matched_identity_idx = None\n",
    "                for i in range(0, len(results), batch_size):\n",
    "                    mean_distance = np.mean(l[i:i+batch_size])\n",
    "                    if mean_distance < threshold:\n",
    "                        matched_identity_idx = i // 5\n",
    "                        print(i, matched_identity_idx)\n",
    "                        break\n",
    "                if matched_identity_idx is None:\n",
    "                    threshold_results.append(None)\n",
    "                else:\n",
    "                    identity_actual = users[matched_identity_idx]\n",
    "                    threshold_results.append(identity_actual)                \n",
    "        else:\n",
    "            threshold_results.append(None)\n",
    "            \n",
    "            \n",
    "    elif method == 'min_distance':        \n",
    "        results = face_recognition.face_distance(encodings_list, encoding)\n",
    "        batch_size = 5\n",
    "        distances = []\n",
    "        for i in range(0, len(results), batch_size):\n",
    "            mean_distance = np.mean(results[i:i+batch_size])\n",
    "            distances.append(mean_distance)\n",
    "        matched_identity_idx = distances.index(np.min(distances))\n",
    "        identity_actual = users[matched_identity_idx]\n",
    "        threshold_results.append(identity_actual)\n",
    "    \n",
    "    \n",
    "    else:        \n",
    "        for i in np.arange(np_ar[0], np_ar[1], np_ar[2]):\n",
    "            results = face_recognition.compare_faces(encodings_list, encoding, tolerance=i)\n",
    "            if True in results:\n",
    "                if method == '5inarow':\n",
    "                    batch_size = 5\n",
    "                    matched_identity_idx = None\n",
    "                    for index in range(0, len(results), batch_size):\n",
    "                        true_num = results[index:index+batch_size].count(True)\n",
    "                        if true_num == 5:\n",
    "                            matched_identity_idx = index // 5\n",
    "                            break\n",
    "                    if matched_identity_idx is None:\n",
    "                        threshold_results.append(None)\n",
    "                    else:\n",
    "                        identity_actual = users[matched_identity_idx]\n",
    "                        threshold_results.append(identity_actual)\n",
    "                        \n",
    "                        \n",
    "                else:\n",
    "                    matched_identity_idx = results.index(True)\n",
    "                    identity_actual = users[matched_identity_idx]\n",
    "                    threshold_results.append(identity_actual)\n",
    "            else:\n",
    "                threshold_results.append(None)\n",
    "    \n",
    "    \n",
    "    return threshold_results \n",
    "\n",
    "\n",
    "def calc_acc(array: list, true_value: int):\n",
    "    \"\"\"\n",
    "        - Takes array of predictions and a `true_value`\n",
    "        - Compares and counts accuracy\n",
    "        - Returns accuracy for a list\n",
    "    \"\"\"\n",
    "    right_preds = 0\n",
    "    for el in array:\n",
    "        if el == true_value:\n",
    "            right_preds += 1\n",
    "    accuracy = right_preds / len(array)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def get_predictions(row, encodings_list, np_ar, method: str, limit: int = 5) -> list:\n",
    "    \"\"\"\n",
    "        - Takes a row of `df_test_encodings` DataFrame\n",
    "        - Goes into a for loop for each encoding and matches it to `encodings` list\n",
    "        - Calls `match_encoding` function\n",
    "    \"\"\"\n",
    "    predictions_for_each_image = []    \n",
    "    for encoding in row['5_encodings']:\n",
    "        results = match_encoding(encodings_list, encoding, np_ar, method)    \n",
    "            \n",
    "        if results is None:\n",
    "            continue        \n",
    "        predictions_for_each_image.append(results)  \n",
    "    return predictions_for_each_image\n",
    "\n",
    "        \n",
    "def get_accuracy_by_threshold(row, results_by_threshold):\n",
    "    \"\"\"\n",
    "        - Takes the dict from `get_results_by_threshold`\n",
    "        - Calculates accuracy for each threshold\n",
    "        - Return accuracies list\n",
    "    \"\"\"\n",
    "    acc_by_threshold = []\n",
    "    for key in results_by_threshold:\n",
    "        acc = calc_acc(results_by_threshold[key], row['identities'])\n",
    "        acc_by_threshold.append(acc)  \n",
    "    return acc_by_threshold\n",
    "\n",
    "\n",
    "def get_accuracy(row, predictions, np_ar, method):\n",
    "    \"\"\"\n",
    "        - Takes the dict from `get_results_by_threshold`\n",
    "        - Calculates accuracy for each threshold\n",
    "        - Return accuracies list\n",
    "    \"\"\"\n",
    "    acc_by_threshold = []\n",
    "    if method == 'min_distance':\n",
    "        acc = calc_acc(predictions[:, 0], row['identities'])\n",
    "        acc_by_threshold.append(acc) \n",
    "    else:\n",
    "        length = len(np.arange(np_ar[0], np_ar[1], np_ar[2]))\n",
    "        for i in range(length):\n",
    "            acc = calc_acc(predictions[:, i], row['identities'])\n",
    "            acc_by_threshold.append(acc)  \n",
    "    return acc_by_threshold\n",
    "\n",
    "\n",
    "def create_accuracy_column(df, encodings_list, np_ar, method: str):\n",
    "    \"\"\"\n",
    "        - Takes `df_test` DataFrame\n",
    "        - Calls `get_predictions`, `get_results_by_threshold`, `get_accuracy_by_threshold`\n",
    "        - Returns list of lists (for each person) with accuracies (for each tolerance threshold)\n",
    "    \"\"\"\n",
    "    accuracy_list = [] \n",
    "    for index, row in df.iloc[8000:8050].iterrows():\n",
    "#     for index, row in df.iterrows():\n",
    "        predictions_for_each_image = get_predictions(row, encodings_list, np_ar, method)        \n",
    "        predictions = np.array(predictions_for_each_image)\n",
    "        print(predictions)\n",
    "        acc_by_threshold = get_accuracy(row, predictions, np_ar, method)\n",
    "        accuracy_list.append(acc_by_threshold)\n",
    "        \n",
    "    return accuracy_list\n",
    "\n",
    "\n",
    "def print_acc_by_threshold(accuracies, np_ar):\n",
    "    accuracies = np.array(accuracies)\n",
    "    \n",
    "    for i, threshold in enumerate(np.arange(np_ar[0], np_ar[1], np_ar[2])):\n",
    "        print(f'Accuracy with {threshold:.3f} threshold: {accuracies[:, i].mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea0ef3",
   "metadata": {},
   "source": [
    "### Measuring accuracy for the Baseline method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "6047b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 45s, sys: 10.7 s, total: 4min 56s\n",
      "Wall time: 4min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "encodings_1_per_person = encodings[::5]\n",
    "identities_accuracies = create_accuracy_column(df_test_read, encodings_1_per_person, np_ar=(0.5, 0.71, 0.1), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "9e85ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.500 threshold: 0.62\n",
      "Accuracy with 0.600 threshold: 0.69\n",
      "Accuracy with 0.700 threshold: 0.11\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies, (0.5, 0.71, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "e840b284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 43s, sys: 10.9 s, total: 4min 54s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_0_55_0_65 = create_accuracy_column(df_test_read, encodings_1_per_person, np_ar=(0.55, 0.66, 0.05), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "6fd0e4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.550 threshold: 0.77\n",
      "Accuracy with 0.600 threshold: 0.69\n",
      "Accuracy with 0.650 threshold: 0.34\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_0_55_0_65, (0.55, 0.66, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "129deed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 47s, sys: 10.9 s, total: 4min 58s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_0_525_0_575 = create_accuracy_column(df_test_read, encodings_1_per_person, np_ar=(0.525, 0.576, 0.025), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "85d0db20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.525 threshold: 0.72\n",
      "Accuracy with 0.550 threshold: 0.77\n",
      "Accuracy with 0.575 threshold: 0.76\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_0_525_0_575, (0.525, 0.576, 0.025))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280d3b87",
   "metadata": {},
   "source": [
    "Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3754a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "identities_accuracies_0_525_0_575 = create_accuracy_column(df_test_read, encodings_1_per_person, np_ar=(0.525, 0.576, 0.025), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ddfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc_by_threshold(identities_accuracies_0_525_0_575, (0.525, 0.576, 0.025))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d230fa17",
   "metadata": {},
   "source": [
    "#### The biggest accuracy was achieved with the threshold of 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0906d",
   "metadata": {},
   "source": [
    "## 3.2 Mean Encoding  \n",
    "- Create one mean encoding from five given encodings for each person\n",
    "- Choose the best tolerance threshold\n",
    "- Maximize the accuracy metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0c698d",
   "metadata": {},
   "source": [
    "#### Creating mean encodigns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "46849dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9283"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = 0\n",
    "temp_encodings = []\n",
    "mean_encodings = []\n",
    "for enc in encodings:\n",
    "    if counter < 5:\n",
    "        temp_encodings.append(enc)\n",
    "        counter += 1\n",
    "        if counter == 5:\n",
    "            mean_enc = np.mean(temp_encodings, axis=0)\n",
    "            mean_encodings.append(mean_enc)\n",
    "            counter = 0\n",
    "            temp_encodings = []\n",
    "\n",
    "len(mean_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "affcb403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 10.3 s, total: 40 s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.5, 0.71, 0.1), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "f7613a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.500 threshold: 0.89\n",
      "Accuracy with 0.600 threshold: 0.22\n",
      "Accuracy with 0.700 threshold: 0.02\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc, (0.5, 0.71, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "6e212262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.9 s, sys: 9.81 s, total: 40.7 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_45_0_55 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.45, 0.551, 0.05), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "f0ef70d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.450 threshold: 0.86\n",
      "Accuracy with 0.500 threshold: 0.89\n",
      "Accuracy with 0.550 threshold: 0.67\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_45_0_55, (0.45, 0.551, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "a347cfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.2 s, sys: 10.2 s, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_475_0_525 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.475, 0.526, 0.025), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "1b4c2caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.475 threshold: 0.49\n",
      "Accuracy with 0.500 threshold: 0.22\n",
      "Accuracy with 0.525 threshold: 0.06\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_475_0_525, (0.475, 0.526, 0.025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "f79ca309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 6s, sys: 10.6 s, total: 1min 17s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_463_0_487 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.463, 0.488, 0.012), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "421ed48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.463 threshold: 0.59\n",
      "Accuracy with 0.475 threshold: 0.49\n",
      "Accuracy with 0.487 threshold: 0.35\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_463_0_487, (0.463, 0.488, 0.012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "152b2096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 15s, sys: 10.2 s, total: 1min 25s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_439_0_463 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.439, 0.464, 0.012), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "4239d05e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.439 threshold: 0.71\n",
      "Accuracy with 0.451 threshold: 0.65\n",
      "Accuracy with 0.463 threshold: 0.59\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_439_0_463, (0.439, 0.464, 0.012))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "dde30efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 10.5 s, total: 1min 29s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_415_0_44 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.415, 0.44, 0.012), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "3c1634bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.415 threshold: 0.70\n",
      "Accuracy with 0.427 threshold: 0.72\n",
      "Accuracy with 0.439 threshold: 0.71\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_415_0_44, (0.415, 0.44, 0.012))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76b164",
   "metadata": {},
   "source": [
    "#### Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "ecd1526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 30min 16s, sys: 49min 22s, total: 5h 19min 39s\n",
      "Wall time: 5h 19min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_mean_enc_0_3_0_5 = create_accuracy_column(df_test_read, mean_encodings, np_ar=(0.3, 0.501, 0.01), method='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "4e179dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.300 threshold: 0.15\n",
      "Accuracy with 0.310 threshold: 0.19\n",
      "Accuracy with 0.320 threshold: 0.24\n",
      "Accuracy with 0.330 threshold: 0.29\n",
      "Accuracy with 0.340 threshold: 0.34\n",
      "Accuracy with 0.350 threshold: 0.40\n",
      "Accuracy with 0.360 threshold: 0.46\n",
      "Accuracy with 0.370 threshold: 0.51\n",
      "Accuracy with 0.380 threshold: 0.56\n",
      "Accuracy with 0.390 threshold: 0.61\n",
      "Accuracy with 0.400 threshold: 0.65\n",
      "Accuracy with 0.410 threshold: 0.69\n",
      "Accuracy with 0.420 threshold: 0.72\n",
      "Accuracy with 0.430 threshold: 0.74\n",
      "Accuracy with 0.440 threshold: 0.74\n",
      "Accuracy with 0.450 threshold: 0.73\n",
      "Accuracy with 0.460 threshold: 0.71\n",
      "Accuracy with 0.470 threshold: 0.65\n",
      "Accuracy with 0.480 threshold: 0.58\n",
      "Accuracy with 0.490 threshold: 0.49\n",
      "Accuracy with 0.500 threshold: 0.39\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_mean_enc_0_3_0_5, (0.3, 0.501, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac296698",
   "metadata": {},
   "source": [
    "The best accuracy with this method was get with 0.43 threshold and equals 74%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f95ffc",
   "metadata": {},
   "source": [
    "## 3.3 Minimum accordance amount\n",
    "- After getting a result from `compare_faces` function, look for 3, 4, 5 True values in a row and return the prediction  \n",
    "- Choose the best `min_accordance` value (3-5)  \n",
    "- Choose the best tolerance threshold  \n",
    "- Maximize the accuracy metric  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "54ec67fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 36s, sys: 17 s, total: 3min 53s\n",
      "Wall time: 3min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_5inarow = create_accuracy_column(df_test_read, encodings, np_ar=(0.4, 0.601, 0.05), method='5inarow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "94efe7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.400 threshold: 0.03\n",
      "Accuracy with 0.450 threshold: 0.12\n",
      "Accuracy with 0.500 threshold: 0.28\n",
      "Accuracy with 0.550 threshold: 0.45\n",
      "Accuracy with 0.600 threshold: 0.42\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_5inarow, (0.4, 0.601, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "f36fcece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 51s, sys: 20.1 s, total: 4min 11s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "identities_accuracies_5inarow_051_056 = create_accuracy_column(df_test_read, encodings, np_ar=(0.51, 0.561, 0.01), method='5inarow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "92b596d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.510 threshold: 0.33\n",
      "Accuracy with 0.520 threshold: 0.36\n",
      "Accuracy with 0.530 threshold: 0.40\n",
      "Accuracy with 0.540 threshold: 0.45\n",
      "Accuracy with 0.550 threshold: 0.45\n",
      "Accuracy with 0.560 threshold: 0.48\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(identities_accuracies_5inarow_051_056, (0.51, 0.561, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc7c212",
   "metadata": {},
   "source": [
    "#### Test on the entire dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "identities_accuracies_5inarow_03_043 = create_accuracy_column(df_test_read, encodings, np_ar=(0.53, 0.641, 0.01), method='5inarow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b19259",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc_by_threshold(identities_accuracies_5inarow_03_043, (0.53, 0.641, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef28419",
   "metadata": {},
   "source": [
    "## 3.4 Face distance  \n",
    "- Use `face_distance` instead of compare faces  \n",
    "- Calculate overall distance by 5 encodings for each person \n",
    "- Choosing the first value, which is lower than the threshold and the corresponding person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "d33fa424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[None]\n",
      " [None]\n",
      " [None]\n",
      " [None]\n",
      " [None]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [680]\u001b[0m, in \u001b[0;36mcreate_accuracy_column\u001b[0;34m(df, encodings_list, np_ar, method)\u001b[0m\n\u001b[1;32m    149\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predictions_for_each_image)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[0;32m--> 151\u001b[0m     acc_by_threshold \u001b[38;5;241m=\u001b[39m \u001b[43mget_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp_ar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     accuracy_list\u001b[38;5;241m.\u001b[39mappend(acc_by_threshold)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_list\n",
      "Input \u001b[0;32mIn [680]\u001b[0m, in \u001b[0;36mget_accuracy\u001b[0;34m(row, predictions, np_ar, method)\u001b[0m\n\u001b[1;32m    132\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39marange(np_ar[\u001b[38;5;241m0\u001b[39m], np_ar[\u001b[38;5;241m1\u001b[39m], np_ar[\u001b[38;5;241m2\u001b[39m]))\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[0;32m--> 134\u001b[0m         acc \u001b[38;5;241m=\u001b[39m calc_acc(\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentities\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    135\u001b[0m         acc_by_threshold\u001b[38;5;241m.\u001b[39mappend(acc)  \n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc_by_threshold\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ident_accs_dist_thresh = create_accuracy_column(df_test_read, encodings, np_ar=(0.3, 0.501, 0.05), method='distance_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "4d0e699e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.300 threshold: 0.16\n",
      "Accuracy with 0.350 threshold: 0.40\n",
      "Accuracy with 0.400 threshold: 0.67\n",
      "Accuracy with 0.450 threshold: 0.66\n",
      "Accuracy with 0.500 threshold: 0.22\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(ident_accs_dist_thresh, (0.3, 0.501, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "8e20f339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 27s, sys: 28 s, total: 3min 55s\n",
      "Wall time: 3min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ident_accs_dist_thresh_038_045 = create_accuracy_column(df_test_read, encodings, np_ar=(0.38, 0.451, 0.01), method='distance_threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "b617cd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 0.380 threshold: 0.57\n",
      "Accuracy with 0.390 threshold: 0.62\n",
      "Accuracy with 0.400 threshold: 0.67\n",
      "Accuracy with 0.410 threshold: 0.69\n",
      "Accuracy with 0.420 threshold: 0.71\n",
      "Accuracy with 0.430 threshold: 0.73\n",
      "Accuracy with 0.440 threshold: 0.71\n",
      "Accuracy with 0.450 threshold: 0.66\n"
     ]
    }
   ],
   "source": [
    "print_acc_by_threshold(ident_accs_dist_thresh_038_045, (0.38, 0.451, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f23d298",
   "metadata": {},
   "source": [
    "## 3.5 Minimum face distance  \n",
    "- Use `face_distance` instead of compare faces  \n",
    "- Calculate overall distance by 5 encodings for each person \n",
    "- Choosing the lowest value and the corresponding person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8115d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "d2e7347c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5h 59min 13s, sys: 13min 51s, total: 6h 13min 5s\n",
      "Wall time: 6h 13min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ident_accs_min_dist = create_accuracy_column(df_test_read, encodings, np_ar=(0.38, 0.451, 0.01), method='min_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "b537a7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85\n"
     ]
    }
   ],
   "source": [
    "print(f'{np.mean(ident_accs_min_dist):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "a151b3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0]    4940\n",
       "[0.8]    1795\n",
       "[0.6]     726\n",
       "[0.4]     360\n",
       "[0.0]     249\n",
       "[0.2]     200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(ident_accs_min_dist).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "6c510b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9129607291247822"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.Series(ident_accs_min_dist).apply(lambda x: x[0])\n",
    "np.mean(res.loc[res > 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "02bab49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7461"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res.loc[res > 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac12c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac4e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a00b43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336fb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65f01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5a204aa",
   "metadata": {},
   "source": [
    "# БУКУК"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6d56e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000004.jpg</td>\n",
       "      <td>5805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>9295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  identity\n",
       "0  000001.jpg      2880\n",
       "1  000002.jpg      2937\n",
       "2  000003.jpg      8692\n",
       "3  000004.jpg      5805\n",
       "4  000005.jpg      9295"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_identity.loc[df_identity['identity'].isin(idx_list)]  # leaving only needed identities\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa9d4f",
   "metadata": {},
   "source": [
    "leaving only 5 images in DataFrame for each identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9ec3099c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.12 s, sys: 3.76 ms, total: 7.12 s\n",
      "Wall time: 7.12 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>identity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>2937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000003.jpg</td>\n",
       "      <td>8692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  identity\n",
       "0  000001.jpg      2880\n",
       "1  000002.jpg      2937\n",
       "2  000003.jpg      8692"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# leave only 5 rows for each identity\n",
    "filenames_fin = []\n",
    "idx_map = {}\n",
    "for index, row in df.iterrows():\n",
    "    if row['identity'] in idx_map.keys():\n",
    "        if idx_map[row['identity']] < 5:\n",
    "            filenames_fin.append(row['filename'])\n",
    "            idx_map[row['identity']] += 1\n",
    "    else:\n",
    "        filenames_fin.append(row['filename'])\n",
    "        idx_map[row['identity']] = 1\n",
    "\n",
    "# leaving images only with the names, which we got on the previous step\n",
    "df5 = df.loc[df['filename'].isin(filenames_fin)]\n",
    "df5.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a10ecf",
   "metadata": {},
   "source": [
    "checking how many identities and images do we left with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "bdd0e1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 9343 identities\n",
      "Each identity has 5 images\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {df5[\"identity\"].value_counts().size} identities'\n",
    "      f'\\nEach identity has {df5[\"identity\"].value_counts().value_counts().index[0]} images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d21f5760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.09392920881509781, 0.16680526733398438, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.13565079867839813, 0.04019104316830635, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.0700308233499527, 0.09956848621368408, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.26122236251831055, 0.11445462703704834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.11555222421884537, 0.05275091528892517, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   identities                                          encodings\n",
       "0        2880  [[-0.09392920881509781, 0.16680526733398438, 0...\n",
       "1        2937  [[-0.13565079867839813, 0.04019104316830635, 0...\n",
       "2        8692  [[-0.0700308233499527, 0.09956848621368408, 0....\n",
       "3        5805  [[-0.26122236251831055, 0.11445462703704834, 0...\n",
       "4        9295  [[-0.11555222421884537, 0.05275091528892517, 0..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = pd.DataFrame(data=data, columns=['identities', 'encodings'])\n",
    "df_fin.to_csv('identities_encodings.csv', index=False)\n",
    "df_fin.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d33a8576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2880</td>\n",
       "      <td>[[-0.09392920881509781, 0.16680526733398438, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2937</td>\n",
       "      <td>[[-0.13565079867839813, 0.04019104316830635, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.0700308233499527, 0.09956848621368408, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.26122236251831055, 0.11445462703704834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9295</td>\n",
       "      <td>[[-0.11555222421884537, 0.05275091528892517, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8910</th>\n",
       "      <td>6223</td>\n",
       "      <td>[[-0.05556920915842056, 0.12527385354042053, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>6258</td>\n",
       "      <td>[[-0.007462053559720516, -0.006663414649665356...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8912</th>\n",
       "      <td>10101</td>\n",
       "      <td>[[-0.0996573269367218, 0.03893882781267166, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>5920</td>\n",
       "      <td>[[-0.20153068006038666, 0.13730086386203766, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>9268</td>\n",
       "      <td>[[-0.10642589628696442, 0.13724175095558167, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8915 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings\n",
       "0           2880  [[-0.09392920881509781, 0.16680526733398438, 0...\n",
       "1           2937  [[-0.13565079867839813, 0.04019104316830635, 0...\n",
       "2           8692  [[-0.0700308233499527, 0.09956848621368408, 0....\n",
       "3           5805  [[-0.26122236251831055, 0.11445462703704834, 0...\n",
       "4           9295  [[-0.11555222421884537, 0.05275091528892517, 0...\n",
       "...          ...                                                ...\n",
       "8910        6223  [[-0.05556920915842056, 0.12527385354042053, 0...\n",
       "8911        6258  [[-0.007462053559720516, -0.006663414649665356...\n",
       "8912       10101  [[-0.0996573269367218, 0.03893882781267166, 0....\n",
       "8913        5920  [[-0.20153068006038666, 0.13730086386203766, 0...\n",
       "8914        9268  [[-0.10642589628696442, 0.13724175095558167, 0...\n",
       "\n",
       "[8915 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_df = pd.read_csv('identities_encodings.csv')\n",
    "read_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9d4a6a",
   "metadata": {},
   "source": [
    "identities with proper amount of encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d7d661e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_df.drop(read_df.loc[read_df['identities'].isin(damaged_rows)].index, inplace=True)\n",
    "len(read_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8646528b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identities</th>\n",
       "      <th>encodings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8692</td>\n",
       "      <td>[[-0.0700308233499527, 0.09956848621368408, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5805</td>\n",
       "      <td>[[-0.26122236251831055, 0.11445462703704834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6369</td>\n",
       "      <td>[[0.03670291602611542, 0.17831860482692719, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>667</td>\n",
       "      <td>[[-0.14975506067276, 0.09124454110860825, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>268</td>\n",
       "      <td>[[-0.11092862486839294, 0.13797610998153687, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8871</th>\n",
       "      <td>8214</td>\n",
       "      <td>[[-0.07532814890146255, 0.1283508688211441, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8879</th>\n",
       "      <td>9549</td>\n",
       "      <td>[[-0.06116217374801636, 0.057062678039073944, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8895</th>\n",
       "      <td>9229</td>\n",
       "      <td>[[-0.17309236526489258, 0.03611578419804573, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>6245</td>\n",
       "      <td>[[-0.10766778141260147, 0.07498753815889359, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8911</th>\n",
       "      <td>6258</td>\n",
       "      <td>[[-0.007462053559720516, -0.006663414649665356...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identities                                          encodings\n",
       "2           8692  [[-0.0700308233499527, 0.09956848621368408, 0....\n",
       "3           5805  [[-0.26122236251831055, 0.11445462703704834, 0...\n",
       "7           6369  [[0.03670291602611542, 0.17831860482692719, -0...\n",
       "16           667  [[-0.14975506067276, 0.09124454110860825, 0.14...\n",
       "30           268  [[-0.11092862486839294, 0.13797610998153687, 0...\n",
       "...          ...                                                ...\n",
       "8871        8214  [[-0.07532814890146255, 0.1283508688211441, 0....\n",
       "8879        9549  [[-0.06116217374801636, 0.057062678039073944, ...\n",
       "8895        9229  [[-0.17309236526489258, 0.03611578419804573, 0...\n",
       "8899        6245  [[-0.10766778141260147, 0.07498753815889359, 0...\n",
       "8911        6258  [[-0.007462053559720516, -0.006663414649665356...\n",
       "\n",
       "[1132 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df_fin.loc[df_fin['identities'].isin(damaged_rows)]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "68493cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 1s, sys: 1.11 s, total: 19min 3s\n",
      "Wall time: 20min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# creating list of all encodings \n",
    "encodings_new = []\n",
    "# list for images, where weren't located any faces\n",
    "errors_new = []\n",
    "seen_images = []\n",
    "data_new = {'identities': [], 'encodings': []}\n",
    "\n",
    "# for identity in df_new['identities'].iloc[:100].values:\n",
    "# be careful with the activation of the line below, it takes almost 2 hours to proceed\n",
    "for identity in df_new['identities'].values:\n",
    "    filenames_list = df_if['filenames'].loc[df_if['identity'] == identity].values[0]\n",
    "    counter = 0\n",
    "    data_new['identities'].append(identity)\n",
    "    temp_encodings = []\n",
    "    for filename in filenames_list:\n",
    "        if counter >= 5:\n",
    "            continue\n",
    "            \n",
    "        encodings_ = image_to_encodings(filename)\n",
    "        seen_images.append(filename)\n",
    "        \n",
    "        # if a face wasn't found or there were more than 1 face\n",
    "        if len(encodings_) != 1:\n",
    "            # try to find another image of the same identity\n",
    "            new_encoding, new_filename = find_new_image(identity, filenames_list)\n",
    "            \n",
    "            # if there wasn't any other photos\n",
    "            if new_encoding is None:\n",
    "                # append an error message\n",
    "                errors_new.append(('problem in:', filename, new_filename, identity, 'solved with:', 'ISN\\'T SOLVED'))\n",
    "            else:\n",
    "                encodings_new.append(new_encoding)\n",
    "                temp_encodings.append(list(new_encoding))\n",
    "                errors_new.append(('problem in:', filename, identity, 'solved with:', new_filename))\n",
    "        else:\n",
    "            encodings_new.append(encodings_[0])\n",
    "            temp_encodings.append(list(encodings_[0]))\n",
    "        \n",
    "        counter += 1\n",
    "    data_new['encodings'].append(json.dumps(temp_encodings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd5113",
   "metadata": {},
   "source": [
    "Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7a005bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1132"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin2 = pd.DataFrame(data=data_new, columns=['identities', 'encodings'])\n",
    "df_fin2.to_csv('identities_encodings_part2.csv', index=False)\n",
    "len(df_fin2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed039dc",
   "metadata": {},
   "source": [
    "Removing those, who had not enough images or the images were corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e6a38165",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = []\n",
    "for error in errors_new:\n",
    "    if error[-1] == \"ISN'T SOLVED\":\n",
    "        drop_list.append(error[3])\n",
    "drop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "839ce77e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1123"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin2 = df_fin2.loc[~df_fin2['identities'].isin(drop_list)]\n",
    "df_fin2.to_csv('identities_encodings_part2.csv', index=False)\n",
    "len(df_fin2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0b1878",
   "metadata": {},
   "source": [
    "Checking the damaged rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "287f797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damaged_rows_new = []\n",
    "\n",
    "for index, row in df_fin2.iterrows():\n",
    "    check_enc_quant(row)\n",
    "\n",
    "len(damaged_rows_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_new = pd.DataFrame(data=data_new, columns=['identities', 'encodings'])\n",
    "# df_fin_new.to_csv('identities_encodings.csv', index=False)\n",
    "df_fin_new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02935423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d037bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_FACES_DIR = 'KNOWN_FACES'\n",
    "UNKNOWN_FACES_DIR = 'UNKNOWN_FACES'\n",
    "TOLERANCE = 0.6\n",
    "FRAME_THIKNESS = 3\n",
    "FONT_THIKNESS = 2\n",
    "MODEL = 'hog'\n",
    "\n",
    "# video = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaff284",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_faces = []\n",
    "known_names = []\n",
    "\n",
    "for name in os.listdir(KNOWN_FACES_DIR):\n",
    "    for filename in os.listdir(f'{KNOWN_FACES_DIR}/{name}'):\n",
    "        image = face_recognition.load_image_file(f'{KNOWN_FACES_DIR}/{name}/{filename}')\n",
    "        encoding = face_recognition.face_encodings(image)\n",
    "        known_faces.append(encoding[0])\n",
    "        known_names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f595c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # print(filename)\n",
    "    # image = face_recognition.load_image_file(f'{UNKNOWN_FACES_DIR}/{filename}')\n",
    "\n",
    "    ret, image = video.read()\n",
    "\n",
    "    print(type(image))\n",
    "    locations = face_recognition.face_locations(image, model=MODEL)\n",
    "    encodings = face_recognition.face_encodings(image, locations)\n",
    "    print(encodings)\n",
    "    print(type(encodings))\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    for face_encoding, face_location in zip(encodings, locations):\n",
    "        results = face_recognition.compare_faces(known_faces, face_encoding, TOLERANCE)\n",
    "        match = None\n",
    "        if True in results:\n",
    "            match = known_names[results.index(True)]\n",
    "            print(f'Match found: {match}')\n",
    "            top_left = (face_location[3], face_location[0])\n",
    "            bottom_right = (face_location[1], face_location[2])\n",
    "            color = [0, 255, 0]\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, FRAME_THIKNESS)\n",
    "\n",
    "            top_left = (face_location[3], face_location[2])\n",
    "            bottom_right = (face_location[1], face_location[2] + 22)\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, cv2.FILLED)\n",
    "            cv2.putText(image, match, (face_location[3] + 10, face_location[2] + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                        (200, 200, 200), FONT_THIKNESS)\n",
    "\n",
    "    cv2.imshow('Webcam', image)\n",
    "    if cv2.waitKey(20) & 0xFF==ord('d'):\n",
    "        break\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyWindow(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4740b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1513cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61c853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9bfb37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9_face_recognition",
   "language": "python",
   "name": "python3.9_face_recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
